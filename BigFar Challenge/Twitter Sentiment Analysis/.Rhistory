table(predict(modelprobit,type = "response")>0.11)
cutsample_pred_res<-insample_pred>.5
cutsample_pred_res<-as.numeric(insample_pred_res)
cost1 <- function(r, pi) {
weight1 = 10
weight0 = 1
c1 = (r == 1) & (pi < pcut)  #logical vector - true if actual 1 but predict 0
c0 = (r == 0) & (pi > pcut)  #logical vecotr - true if actual 0 but predict 1
return(mean(weight1 * c1 + weight0 * c0))
}
for (i in 1:length(searchgrid)) {
pcut <- result[i, 1]
# assign the cost to the 2nd col
result[i, 2] <- cost1(training$response, predict(modelprobit, type = "response"))
}
plot(result, ylab = "Cost in Training Set")
ind<-which(result[,2]==min(result[,2]),TRUE)
cutsample_pred_res<-insample_pred>.11
cutsample_pred_res<-as.numeric(insample_pred_res)
table(testing$response,cutsample_pred_res,dnn=c("Truth","Predicted"))
hist(insample_pred)
insample_pred<-predict(modelprobit,type="response")
hist(insample_pred)
cutsample_pred_res<-insample_pred>.11
cutsample_pred_res<-as.numeric(insample_pred_res)
table(testing$response,cutsample_pred_res,dnn=c("Truth","Predicted"))
outsample_pred<-predict(modelprobit,testing,type="response")
outsample_pred<-predict(modelprobit,testing,type="response")
hist(outsample_pred)
cutsample_pred_res<-outsample_pred>.11
cutsample_pred_res<-as.numeric(outsample_pred_res)
table(testing$response,cutsample_pred_res,dnn=c("Truth","Predicted"))
mean(ifelse(testing$response!=cutsample_pred_res,1,0))
roc.plot(testing$response=="1",outsample_pred,main="Outsample ROC curve for final model")$roc.vol
cost2 <- function(r, pi) {
weight1 = 5
weight0 = 1
c1 = (r == 1) & (pi < cutoff)  #logical vector - true if actual 1 but predict 0
c0 = (r == 0) & (pi > cutoff)  #logical vecotr - true if actual 0 but predict 1
return(mean(weight1 * c1 + weight0 * c0))
}
cost2 <- function(r, pi) {
weight1 = 5
weight0 = 1
c1 = (r == 1) & (pi < cutoff)  #logical vector - true if actual 1 but predict 0
c0 = (r == 0) & (pi > cutoff)  #logical vecotr - true if actual 0 but predict 1
return(mean(weight1 * c1 + weight0 * c0))
}
crossvalidation<-cv.glm(data = german_credit,modelprobit,cost2,3)
modelprobitcv<-glm(response~amount+foreign+sex+housing+age+installment_rate+other_debtor+other_install+credit_his+saving_acct+purpose+chk_acct,data = training,family = binomial(link = "probit"))
crossvalidation<-cv.glm(data = german_credit,modelprobitcv,cost2,3)
crossvalidation$delta[,2]
crossvalidation$delta
crossvalidation<-cv.glm(data = german_credit,modelprobitcv,cost2,k=3)
crossvalidation<-cv.glm(data = german_credit,glmfit =modelprobitcv,cost2,k=3)
crossvalidation<-cv.glm(data = german_credit,glmfit =modelprobitcv,k=3)
crossvalidation<-cv.glm(data = german_credit,glmfit =modelprobitcv)
crossvalidation<-cv.glm(data = german_credit,glmfit =modelprobitcv,cost = cost2,k=3)
crossvalidation<-cv.glm(data = german_credit,glmfit =modelprobitcv,cost = cost2)
crossvalidation<-cv.glm(data = german_credit,glmfit =modelprobitcv,cost = cost2,k=3)
crossvalidation$delta
library(validation)
library(boot)
modelprobitcv<-glm(response~amount+foreign+sex+housing+age+installment_rate+other_debtor+other_install+credit_his+saving_acct+purpose+chk_acct,data = training,family = binomial(link = "probit"))
crossvalidation<-cv.glm(data = german_credit,glmfit =modelprobitcv,cost = cost2,k=3)
faa<-read.csv(file = /Users/akashjain/Google Drive/Workplace/Cincinnati/BANA 6043 Stat Computing)
faa<-read.csv(file = \Users\akashjain\Google Drive\Workplace\Cincinnati\BANA 6043 Stat Computing)
faa<-read.csv(file = "/Users/akashjain/Google Drive/Workplace/Cincinnati/BANA 6043 Stat Computing",header = TRUE)
faa<-read.csv(file = "/Users/akashjain/Google Drive/Workplace/Cincinnati/BANA 6043 Stat Computing",header = TRUE)
faa<-read.csv(file = "/Users/akashjain/Google Drive/Workplace/Cincinnati/BANA 6043 Stat Computing/xid-54310417_1.csv",header = TRUE)
ncol(faa)
colnames(faa)
nrows(faa)
nrow(faa)
sum(faa[type="airbus"])
str(faa)
faa[1]
faa[type]
faa["type"]
faa["type=airbus"]
faa["type==airbus"]
faa["type"]=="Airbus"
sum(as.numeric(faa["type"]=="Airbus"))
summary(faa)
hist(faa$type)
hist(faa$duration)
hist(faa$no_psng)
hist(faa$speed_ground)
hist(faa$speed_air)
hist(faa$height)
hist(faa$pitch)
faa$type<- as.factor(faa$type)
hist(faa$type)
sum(is.na(faa))
sum(is.na[faa$type])
sum(is.na(faa$type))
summary(faa)
faa$airflow<-faa$speed_ground-faa$speed_air
faa$airflow
sum(is.neumeric(faa["duration"]<40))
sum(is.numeric(faa["duration"]<40))
sum(is.numeric(faa["height"]<6))
faa$height<6
sum(is.numeric(faa$duration<40))
sum(as.numeric(faa$duration<40))
sum(as.numeric(faa$height<6))
sum(as.numeric(faa$type=="Airbus"))
?subset
faa_airbus<-subset(faa,faa$type=="Airbus")
faa_airbus<-subset(faa,faa$type=="Boeing")
faa_boeing<-subset(faa,faa$type=="Boeing")
faa_boeing
summary(faa_airbus)
summary(faa_boeing)
faa<-faa[!(faa$duration<40 & faa$height<40)]
faa<-faa[!(faa$duration<40 & faa$height<40),]
faa_airbus<-subset(faa,faa$type=="Airbus")
faa_boeing<-subset(faa,faa$type=="Boeing")
summary(faa_airbus)
str(faa)
mpar(mfrow=c(2,6))
par(mfrow=c(2,6))
faa$airflow<-abs(faa$speed_ground-faa$speed_air)
faa$airflow
mean(faa$airflow)
avg(faa$airflow)
mean(faa[!(is.na(faa$airflow))])
faa$airflow<-abs(faa$speed_ground-faa$speed_air)
mean(faa[!(is.na(faa$airflow))])
mean(faa[!(faa$airflow==NA)])
mean(faa[!(is.na(faa$airflow)),])
faa[!(is.na(faa$airflow)),]
faa$airflow(obs=10)
head(faa$airflow)
faa["speed_ground"]
faa[!(is.na("speed_ground")]
faa[!(is.na("speed_ground"))]
airflow<-abs(faa[!(is.na("speed_ground"))]-faa[!(is.na("speed_air"))])
faa[!(is.na("speed_ground"))]-faa[!(is.na("speed_air"))]
airflow<-airflow(!is.na(airflow))
airflow<-faa$speed_ground-faa$speed_air
airflow<-airflow(!is.na(airflow))
airflow<-airflow[!is.na(airflow)]
mean(airflow)
unlink('Google Drive/Workplace/Cincinnati/BANA 6043 Stat Computing/Assignment and Mid Term/Homework 6_cache', recursive = TRUE)
---
title: "Assignment 6"
author: "Akash Jain, jain2ar"
date: "2/18/2017"
---
## Question 1: Import the CSV file ‘FAA_r.csv’ using the function “read.table()” or “read.csv()”. Where to find the instruction on how to use the functions?
### Solution:
**R code to import the dataset**
faa<-read.csv(file = "/Users/akashjain/Google Drive/Workplace/Cincinnati/BANA 6043 Stat Computing/xid-54310417_1.csv",header = TRUE)
**R code to find instruction on the use of function**
?read.csv
## Question 2: How many variables in the data set? What are their names?
### Solution:
**R code to get varaible count and name of variables**
str(faa)
There are 7 variables in the dataset and their names are: *type, duration, no_pasg, speed_ground, speed_air, height, pitch*.
### Question 3: How many observations in total? How many observations for Airbus?
### Solution:
**R code to get the total number of obsevartions in dataset**
nrow(faa)
**R code to get the total observations of Airbus**
sum(as.numeric(faa$type=="Airbus"))
## Question 4: Calculate the mean for each of the flight parameters (measures). Please also report the corresponding standard deviation.
### Solution:
**R code to get the mean and standard deviation of each variable**
summary(faa)
## Question 5: Obtain the histogram for each of the flight parameters.
### Solution:
**R code to get the histograms of all the parameters**
par(mfrow=c(2,6))
hist(faa$duration, main = "Histogram of duration")
hist(faa$no_psng, main= "Histogram of no_pasg")
hist(faa$speed_ground, main="Histogram of speed_ground")
hist(faa$speed_air, main="Histogram of speed_air")
hist(faa$height, main="Histogram of height")
hist(faa$pitch, main="Histogram of pitch")
## Question 6: Is there any missing value in the data set? If yes, which variable? What is the proportion of missing values? By exploring the data, can you see the pattern of missing values? In other words, when the values are missing?
### Solution:
**R code to find the if missing values exist in dataset**
sum(is.na(faa))
**R code to find the proportion of missing values**
sum(is.na(faa))/nrow(faa)
**R code to check which column has the missing values**
summary(faa)
## Question 7: Calculate the speed of the air flow (defined as the difference between speed_ground and speed_air). What is the average speed of the air flow? Note the speed should be positive.
### Solution:
**R code to calculate airflow**
airflow<-abs(faa$speed_ground-faa$speed_air)
airflow<-airflow[!is.na(airflow)]
head(faa$airflow)
**R code to claculate the mean of airflow**
mean(airflow)
## Question 8: How many flights have duration less than 40 minutes? How many flights have height less than 6 meters? Please delete those observations from the data set.
### Solution:
**R code to get the number of flights with duration less than 40 minutes**
sum(as.numeric(faa$duration<40))
**R code to get the number of flights with height less than 6 meters**
sum(as.numeric(faa$height<6))
**R code to delete the observations with height less than 6 meters and duration less than 40 minutes**
faa<-faa[!(faa$duration<40 & faa$height<40),]
## Question 9: Divide the cleaned data set (as obtained in Step 8) into two subsets: Airbus and Boeing.
### Solution:
**R code to make two subsets: Airbus and Boeing**
Airbus<-subset(faa,faa$type=="Airbus")
Boeing<-subset(faa,faa$type=="Boeing")
## Question 10: Is there any difference between these two aircraft makes (in terms of speed, height, pitch)?
### Solution:
summary(faa_airbus)
summary(faa_boeing)
data<-read.csv(file = "/Users/akashjain/Google Drive/Workplace/Cincinnati/IS7036 Data Mining for BI/Project/LoanStats3aEdited_backup.csv", header = TRUE)
data
str(data)
data<-read.csv(file = "/Users/akashjain/Google Drive/Workplace/Cincinnati/IS7036 Data Mining for BI/Project/LoanStats3aEdited_backup.csv", header = TRUE)
str(data)
a<-as.numeric(data$emp_length)
a
data<-read.csv(file = "/Users/akashjain/Google Drive/Workplace/Cincinnati/IS7036 Data Mining for BI/Project/LoanStats3aEdited_backup.csv", header = TRUE)
str(data)
data<-read.csv(file = "/Users/akashjain/Google Drive/Workplace/Cincinnati/IS7036 Data Mining for BI/Project/LoanStats3aEdited_backup.csv", header = TRUE)
str(data)
data<-read.csv(file = "/Users/akashjain/Google Drive/Workplace/Cincinnati/IS7036 Data Mining for BI/Project/LoanStats3aEdited_backup.csv", header = TRUE)
str(data)
sample1 = data[sample(x = nrow(data), size = nrow(data)*0.60),]
datasample<-data[,sample1]
sample1
kfit = kmeans(sample1[,-c(sample1$loan_status,sample1$loan_status_coded)], 4)
is.na(sample1)
summary(sample1)
?ifelse
?if
??if
??if
??if
bankruptcies<-ifelse(sample1$pub_rec_bankruptcies==NA,yes = 0,)
bankruptcies<-ifelse(sample1$pub_rec_bankruptcies==NA,yes = 0,sample1$pub_rec_bankruptcies)
bankruptcies
kfit = kmeans(sample1[,-c(sample1$loan_status,sample1$loan_status_coded,sample1$pub_rec_bankruptcies)], 4)
kfit = kmeans(sample1[1:4], 4)
kfit = kmeans(sample1[,1:4], 4)
kfit = kmeans(sample1[,1], 1)
plotcluster(iris_sample[,1:4], kfit$cluster)
attach(sample1)
library(fpc)
kfit = kmeans(sample1[,1], 1)
plotcluster(iris_sample[,1:4], kfit$cluster)
plotcluster(sample1[,1], kfit$cluster)
kfit = kmeans(sample1[,1], 1)
plotcluster(sample1[,1], kfit$cluster)
data<-read.csv(file="/Users/akashjain/Google Drive/Workplace/Cincinnati/IS7036 Data Mining for BI/Project/Telemarketing/bank-additional/bank-additional-full.csv", header = TRUE)
str(data)
attach(data)
plot(age,y)
plot(age.y)
plot(age,y)
plot(age,y)
plot(y,age)
library(ggplot2)
qplot(job,y,data,color=y)
qplot(age, binwidth = 1, fill = factor(y))
qplot(job, binwidth = 1, fill = factor(y))
qplot(job, fill = factor(y))
qplot(marital, fill = factor(y))
qplot(education, fill = factor(y))
qplot(age, binwidth = 1, fill = factor(y))
qplot(default, fill = factor(y))
qplot(duration,binwidth=1, fill = factor(y))
qplot(duration,binwidth=10, fill = factor(y))
qplot(duration,binwidth=1000, fill = factor(y))
qplot(campaign,binwidth=10 fill = factor(y))
qplot(campaign,binwidth=10, fill = factor(y))
qplot(campaign,binwidth=10, fill = factor(y))
qplot(pdays,,binwidth=20, fill = factor(y))
qplot(pdays,binwidth=20, fill = factor(y))
qplot(pdays,binwidth=2, fill = factor(y))
qplot(pdays,binwidth=100, fill = factor(y))
qplot(cons.price.idx,binwidth=10, fill = factor(y))
qplot(cons.conf.idx,binwidth=1, fill = factor(y))
qplot(nr.employed,binwidth=1, fill = factor(y))
qplot(nr.employed,binwidth=10, fill = factor(y))
library(fpc)
clusters<-kmeans(data[,-c(age,pdays,y)],2)
clusters<-kmeans(data[,2:4],2)
clusters<-kmeans(data[,],2)
summary(data)
clusters<-kmeans(data[,c(duration)],2)
clusters<-kmeans(data[,"duration"],2)
plotcluster(data[,"duration"],clusters$cluster)
clusters<-kmeans(data[,"duration,job"],2)
plotcluster(data[,c(duration,job)],clusters$cluster)
clusters<-kmeans(data[,c(duration,job)],2)
plot(data)
clusters<-kmeans(data[,1:7],2)
qplot(age, binwidth = 1, fill = factor(y))
databank<-read.csv(file="/Users/akashjain/Google Drive/Workplace/Cincinnati/IS7036 Data Mining for BI/Project/Telemarketing/bank-full - Copy.csv", header = TRUE)
qplot(y, age, data = databank, geom = "boxplot")+geom_boxplot(aes(fill = y))+ggtitle("Boxplot of Age")
library(ggplot2)
qplot(y, age, data = databank, geom = "boxplot")+geom_boxplot(aes(fill = y))+ggtitle("Boxplot of Age")
qplot(y, balance, data = databank, geom = "boxplot")+geom_boxplot(aes(fill = y))+ggtitle("Boxplot of Balance")
qplot(age, binwidth = 10, fill = factor(y))
attach(databank)
qplot(age, binwidth = 10, fill = factor(y))
qplot(month, fill = factor(y))
library(ggplot2)
qplot(month, fill = factor(y))
databank<-read.csv(file="/Users/akashjain/Google Drive/Workplace/Cincinnati/IS7036 Data Mining for BI/Project/Telemarketing/bank-full - Copy.csv", header = TRUE)
str(databank)
attach(databank)
qplot(month, fill = factor(y))
databank<-read.csv(file="/Users/akashjain/Google Drive/Workplace/Cincinnati/IS7036 Data Mining for BI/Project/Telemarketing/bank-full - Copy.csv", header = TRUE)
?boxplot
data(emptycars)
a<-data(mtcars)
a
load(iris)
a<-[1,2,3,4,5]
a<-c(1,2,3,4,5)
a
boxplot(a)
?boxplot
setwd("/Users/akashjain/Desktop/BigFar Challenge/Twitter Sentiment Analysis")
install.packages("devtools")
require(devtools)
install_url("https://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz")
library(sentiment)
install.packages("Rstem")
?Rstem
library(plyr)
library(ggplot2)
install.packages("wordcloud")
install.packages(Rstem, repos = "http://www.omegahat.net/R")
install_url("https://cran.r-project.org/src/contrib/Archive/slam/slam_0.1-37.tar.gz")
install_url("http://www.omegahat.net/Rstem/")
install_url("http://www.omegahat.net/Rstem/Rstem_0.4-1.tar.gz")
require(Rstem)
install_url("https://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz")
library(sentiment)
install_url("https://cran.r-project.org/src/contrib/Archive/slam/slam_0.1-37.tar.gz")
library(RColorBrewer)
demonetization = read.csv(file ="demonetization" ,header = TRUE)
getwd()
demonetization = read.csv(file ="demonetization.csv" ,header = TRUE)
Demonetization_text = sapply(Demonetization_tweets, function(x) x$getText())
#Prepare/clean data for sentiment analysis
# delete re-tweet entries
Demonetization_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", Demonetization_text)
# remove @ word
Demonetization_text = gsub("@\\w+", "", Demonetization_text)
# delete punctuation
Demonetization_text = gsub("[[:punct:]]", "", Demonetization_text )
# remove Digits: 0 1 2 3 4 5 6 7 8 9
Demonetization_text = gsub("[[:digit:]]", "", Demonetization_text)
# delete html links
Demonetization_text = gsub("http\\w+", "", Demonetization_text)
# delete unnecessary spaces like tab and space
Demonetization_text = gsub("[ \t]{2,}", "", Demonetization_text)
Demonetization_text = gsub("^\\s+|\\s+$", "", Demonetization_text)
Demonetizaion_tweets = read.csv(file ="demonetization.csv" ,header = TRUE)
Demonetization_text = sapply(Demonetization_tweets, function(x) x$getText())
Demonetization_tweets = read.csv(file ="demonetization.csv" ,header = TRUE)
# filter text from tweets
Demonetization_text = sapply(Demonetization_tweets, function(x) x$getText())
#Prepare/clean data for sentiment analysis
# delete re-tweet entries
Demonetization_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", Demonetization_text)
# remove @ word
Demonetization_text = gsub("@\\w+", "", Demonetization_text)
# delete punctuation
Demonetization_text = gsub("[[:punct:]]", "", Demonetization_text )
# remove Digits: 0 1 2 3 4 5 6 7 8 9
Demonetization_text = gsub("[[:digit:]]", "", Demonetization_text)
# delete html links
Demonetization_text = gsub("http\\w+", "", Demonetization_text)
# delete unnecessary spaces like tab and space
Demonetization_text = gsub("[ \t]{2,}", "", Demonetization_text)
Demonetization_text = gsub("^\\s+|\\s+$", "", Demonetization_text)
Demonetization_text = sapply(Demonetization_tweets, function(x) x$getText())
Demonetization_text = sapply(Demonetization_tweets, function(x) x$text)
Demonetization_tweets
type(Demonetization_tweets)
class(Demonetization_tweets)
Demonetization_text = Demonetization_tweets$text
Demonetization_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", Demonetization_text)
Demonetization_text = gsub("@\\w+", "", Demonetization_text)
Demonetization_text = gsub("[[:punct:]]", "", Demonetization_text )
Demonetization_text = gsub("[[:digit:]]", "", Demonetization_text)
Demonetization_text = gsub("http\\w+", "", Demonetization_text)
Demonetization_text = gsub("[ \t]{2,}", "", Demonetization_text)
Demonetization_text = gsub("^\\s+|\\s+$", "", Demonetization_text)
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
Demonetization_text = sapply(Demonetization_text, try.error)
# remove NAs in Demonetization_text
Demonetization_text = Demonetization_text [!is.na(Demonetization_text)]
names(Demonetization_text) = NULL
class_emo = classify_emotion(Demonetization_text, algorithm="bayes", prior=1.0)
# get emotion best fit
emotion = class_emo[,7]
# replace NA's by "unknown"
emotion[is.na(emotion)] = "unknown"
# function classify_polarity is defined in “sentiment” package.
# The classify_polarity function allows us to classify some text as positive or negative
class_pol = classify_polarity(Demonetization_text, algorithm="bayes")
# get polarity best fit
polarity = class_pol[,4]
# Create data frame with the results and obtain some general statistics
# data frame with results
sent_df = data.frame(text= Demonetization_text, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
# plot distribution of emotions
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets") +
labs(title = "Sentiment Analysis of Tweets about Demonetization\n(classification by emotion)")
emotion = class_emo[,7]
emotion[is.na(emotion)] = "unknown"
class_pol = classify_polarity(Demonetization_text, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text= Demonetization_text, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets") +
labs(title = "Sentiment Analysis of Tweets about Demonetization\n(classification by emotion)")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="Dark2") +
labs(x="polarity categories", y="number of tweets") +
labs(title = "Sentiment Analysis of Tweets about Demonetization\n(classification by polarity)")
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = Demonetization_text[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
# remove stopwords
emo.docs = removeWords(emo.docs, stopwords("english"))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
Demonetization_tweets = read.csv(file ="Demonetizationfinal.csv" ,header = TRUE)
Demonetization_text = Demonetization_tweets$text
Demonetization_text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", Demonetization_text)
Demonetization_text = gsub("@\\w+", "", Demonetization_text)
Demonetization_text = gsub("[[:punct:]]", "", Demonetization_text )
Demonetization_text = gsub("[[:digit:]]", "", Demonetization_text)
Demonetization_text = gsub("http\\w+", "", Demonetization_text)
Demonetization_text = gsub("[ \t]{2,}", "", Demonetization_text)
Demonetization_text = gsub("^\\s+|\\s+$", "", Demonetization_text)
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
Demonetization_text = sapply(Demonetization_text, try.error)
Demonetization_text = Demonetization_text [!is.na(Demonetization_text)]
names(Demonetization_text) = NULL
class_emo = classify_emotion(Demonetization_text, algorithm="bayes", prior=1.0)
emotion = class_emo[,7]
emotion[is.na(emotion)] = "unknown"
emotion[is.na(emotion)] = "unknown"
class_pol = classify_polarity(Demonetization_text, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text= Demonetization_text, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets") +
labs(title = "Sentiment Analysis of Tweets about Demonetization\n(classification by emotion)")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="Dark2") +
labs(x="polarity categories", y="number of tweets") +
labs(title = "Sentiment Analysis of Tweets about Demonetization\n(classification by polarity)")
